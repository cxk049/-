{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_base_ = [\n",
    "    '../_base_/models/faster_rcnn_r50_fpn.py',\n",
    "    '../_base_/datasets/voc0712.py',\n",
    "    '../_base_/schedules/schedule_1x.py', '../_base_/default_runtime.py'\n",
    "]\n",
    "model = dict(roi_head=dict(bbox_head=dict(num_classes=20)))\n",
    "# 使用VOC2007和VOC2012数据集\n",
    "data = dict(\n",
    "    train=dict(\n",
    "        type='RepeatDataset',\n",
    "        times=3,\n",
    "        dataset=dict(\n",
    "            type='VOCDataset',\n",
    "            ann_file=[\n",
    "                'data/VOCdevkit/VOC2007/ImageSets/Main/trainval.txt',\n",
    "                'data/VOCdevkit/VOC2012/ImageSets/Main/trainval.txt'\n",
    "            ],\n",
    "            img_prefix=['data/VOCdevkit/VOC2007/', 'data/VOCdevkit/VOC2012/']\n",
    "        )\n",
    "    ),\n",
    "    val=dict(\n",
    "        type='VOCDataset',\n",
    "        ann_file='data/VOCdevkit/VOC2007/ImageSets/Main/val.txt',\n",
    "        img_prefix='data/VOCdevkit/VOC2007/'),\n",
    "    test=dict(\n",
    "        type='VOCDataset',\n",
    "        ann_file='data/VOCdevkit/VOC2007/ImageSets/Main/test.txt',\n",
    "        img_prefix='data/VOCdevkit/VOC2007/'))\n",
    "evaluation = dict(interval=1, metric='mAP')\n",
    "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "lr_config = dict(step=[8, 16])\n",
    "runner = dict(type='EpochBasedRunner', max_epochs=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_base_ = './yolov3_d53_mstrain-608_273e.py'\n",
    "# 使用VOC2007和VOC2012数据集\n",
    "dataset_type = 'VOCDataset'\n",
    "data_root = 'data/VOCdevkit/'\n",
    "\n",
    "data = dict(\n",
    "    train=dict(\n",
    "        type='RepeatDataset',\n",
    "        times=3,\n",
    "        dataset=dict(\n",
    "            type=dataset_type,\n",
    "            ann_file=[\n",
    "                data_root + 'VOC2007/ImageSets/Main/trainval.txt',\n",
    "                data_root + 'VOC2012/ImageSets/Main/trainval.txt'\n",
    "            ],\n",
    "            img_prefix=[data_root + 'VOC2007/', data_root + 'VOC2012/']\n",
    "        )\n",
    "    ),\n",
    "    val=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'VOC2007/ImageSets/Main/val.txt',\n",
    "        img_prefix=data_root + 'VOC2007/'),\n",
    "    test=dict(\n",
    "        type=dataset_type,\n",
    "        ann_file=data_root + 'VOC2007/ImageSets/Main/test.txt',\n",
    "        img_prefix=data_root + 'VOC2007/'))\n",
    "evaluation = dict(interval=1, metric='mAP')\n",
    "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
    "lr_config = dict(step=[8, 16])\n",
    "runner = dict(type='EpochBasedRunner', max_epochs=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mmcv import Config\n",
    "from mmdet.apis import set_random_seed, train_detector\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.apis import train_detector, init_random_seed\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import mmcv\n",
    "\n",
    "def main(config_file, checkpoint=None):\n",
    "    cfg = Config.fromfile(config_file)\n",
    "    cfg.gpu_ids = range(1)\n",
    "    cfg.seed = init_random_seed(0, device='cuda')\n",
    "    set_random_seed(0, deterministic=False)\n",
    "    \n",
    "    # Create work_dir for saving checkpoints and logs\n",
    "    mmcv.mkdir_or_exist(os.path.abspath(cfg.work_dir))\n",
    "    log_file = os.path.join(cfg.work_dir, 'train.log')\n",
    "    writer = SummaryWriter(log_dir=cfg.work_dir)\n",
    "    \n",
    "    # Build dataset and model\n",
    "    datasets = [build_dataset(cfg.data.train)]\n",
    "    model = build_detector(cfg.model)\n",
    "    model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "    # Train the detector\n",
    "    train_detector(model, datasets, cfg, distributed=False, validate=True, meta=dict())\n",
    "    \n",
    "    # Close the SummaryWriter\n",
    "    writer.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Train a detector')\n",
    "    parser.add_argument('config', help='train config file path')\n",
    "    parser.add_argument('--checkpoint', help='checkpoint file')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args.config, args.checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mmcv import Config\n",
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "\n",
    "def main(config_file, checkpoint_file, img_folder, out_folder):\n",
    "    cfg = Config.fromfile(config_file)\n",
    "    model = init_detector(cfg, checkpoint_file, device='cuda:0')\n",
    "\n",
    "    if not os.path.exists(out_folder):\n",
    "        os.makedirs(out_folder)\n",
    "\n",
    "    for img_file in os.listdir(img_folder):\n",
    "        img_path = os.path.join(img_folder, img_file)\n",
    "        result = inference_detector(model, img_path)\n",
    "        out_file = os.path.join(out_folder, img_file)\n",
    "        show_result_pyplot(model, img_path, result, out_file=out_file)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Test a detector')\n",
    "    parser.add_argument('config', help='test config file path')\n",
    "    parser.add_argument('checkpoint', help='checkpoint file')\n",
    "    parser.add_argument('img_folder', help='folder of images to test')\n",
    "    parser.add_argument('out_folder', help='folder to save results')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args.config, args.checkpoint, args.img_folder, args.out_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mmcv import Config\n",
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "import cv2\n",
    "\n",
    "def visualize_proposals(config_file, checkpoint_file, img_folder, out_folder, score_thr=0.5):\n",
    "    cfg = Config.fromfile(config_file)\n",
    "    model = init_detector(cfg, checkpoint_file, device='cuda:0')\n",
    "    proposal_model = model.rpn_head\n",
    "\n",
    "    if not os.path.exists(out_folder):\n",
    "        os.makedirs(out_folder)\n",
    "\n",
    "    for img_file in os.listdir(img_folder):\n",
    "        img_path = os.path.join(img_folder, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        proposals = proposal_model.simple_test_rpn([img], [cfg.data.test.pipeline], rescale=False)\n",
    "        proposals = proposals[0][:, :4]\n",
    "        for box in proposals:\n",
    "            cv2.rectangle(img, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), (0, 255, 0), 2)\n",
    "\n",
    "        out_file = os.path.join(out_folder, 'proposals_' + img_file)\n",
    "        cv2.imwrite(out_file, img)\n",
    "\n",
    "        result = inference_detector(model, img_path)\n",
    "        show_result_pyplot(model, img_path, result, score_thr=score_thr, out_file=os.path.join(out_folder, img_file))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Visualize proposals and detection results')\n",
    "    parser.add_argument('config', help='test config file path')\n",
    "    parser.add_argument('checkpoint', help='checkpoint file')\n",
    "    parser.add_argument('img_folder', help='folder of images to test')\n",
    "    parser.add_argument('out_folder', help='folder to save results')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    visualize_proposals(args.config, args.checkpoint, args.img_folder, args.out_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mmcv import Config\n",
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "\n",
    "def main(config_file, checkpoint_file, img_folder, out_folder):\n",
    "    cfg = Config.fromfile(config_file)\n",
    "    model = init_detector(cfg, checkpoint_file, device='cuda:0')\n",
    "\n",
    "    if not os.path.exists(out_folder):\n",
    "        os.makedirs(out_folder)\n",
    "\n",
    "    for img_file in os.listdir(img_folder):\n",
    "        img_path = os.path.join(img_folder, img_file)\n",
    "        result = inference_detector(model, img_path)\n",
    "        out_file = os.path.join(out_folder, img_file)\n",
    "        show_result_pyplot(model, img_path, result, out_file=out_file)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Test a detector on custom images')\n",
    "    parser.add_argument('config', help='test config file path')\n",
    "    parser.add_argument('checkpoint', help='checkpoint file')\n",
    "    parser.add_argument('img_folder', help='folder of images to test')\n",
    "    parser.add_argument('out_folder', help='folder to save results')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args.config, args.checkpoint, args.img_folder, args.out_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir work_dirs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
